{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f852be06",
      "metadata": {},
      "source": [
        "# Bitcoin Puzzle 71 - GPU Optimized Solver (Kaggle)\n",
        "\n",
        "**Vers√£o otimizada para GPU com algoritmos gen√©ticos avan√ßados**\n",
        "\n",
        "Este notebook foi otimizado para execu√ß√£o em Kaggle com foco em:\n",
        "- Acelera√ß√£o GPU com PyTorch\n",
        "- Algoritmos gen√©ticos inteligentes\n",
        "- Busca adaptativa em espa√ßo de chaves\n",
        "- Detec√ß√£o autom√°tica de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cedbbcf7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 1: Configura√ß√£o Inicial e Detec√ß√£o de Ambiente\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "import platform\n",
        "from pathlib import Path\n",
        "\n",
        "class EnvironmentDetector:\n",
        "    @staticmethod\n",
        "    def detect_environment():\n",
        "        env_info = {\n",
        "            'platform': platform.system(),\n",
        "            'is_kaggle': 'KAGGLE_KERNEL_RUN_TYPE' in os.environ,\n",
        "            'is_colab': 'COLAB_GPU' in os.environ,\n",
        "            'has_gpu': False,\n",
        "            'gpu_count': 0\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            import torch\n",
        "            env_info['has_gpu'] = torch.cuda.is_available()\n",
        "            env_info['gpu_count'] = torch.cuda.device_count()\n",
        "            if env_info['has_gpu']:\n",
        "                env_info['gpu_name'] = torch.cuda.get_device_name(0)\n",
        "        except:\n",
        "            pass\n",
        "            \n",
        "        # For√ßar o modo GPU no Kaggle mesmo que n√£o esteja detectando corretamente\n",
        "        if env_info['is_kaggle'] and not env_info['has_gpu']:\n",
        "            print(\"‚ö†Ô∏è Ambiente Kaggle detectado, mas GPU n√£o detectada pelo PyTorch.\")\n",
        "            print(\"üîÑ For√ßando configura√ß√£o para 2 GPUs (padr√£o do Kaggle)...\")\n",
        "            env_info['has_gpu'] = True\n",
        "            env_info['gpu_count'] = 2\n",
        "            env_info['gpu_name'] = \"Tesla P100\" # GPU comum no Kaggle\n",
        "            \n",
        "        return env_info\n",
        "\n",
        "# Detectar ambiente\n",
        "env = EnvironmentDetector.detect_environment()\n",
        "print(f\"Ambiente: {env}\")\n",
        "\n",
        "# Instalar depend√™ncias se necess√°rio\n",
        "required_packages = ['torch', 'numpy', 'hashlib', 'ecdsa', 'base58']\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "    except ImportError:\n",
        "        if package == 'torch':\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torch', 'torchvision', '--index-url', 'https://download.pytorch.org/whl/cu118'])\n",
        "        else:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b46f3db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 2: Importa√ß√µes e Configura√ß√µes GPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.multiprocessing as mp\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import time\n",
        "import random\n",
        "from typing import List, Tuple, Optional\n",
        "import logging\n",
        "import concurrent.futures\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configura√ß√µes Multi-GPU\n",
        "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "FORCE_GPU = IS_KAGGLE  # For√ßar uso de GPU no Kaggle mesmo que n√£o esteja detectando corretamente\n",
        "GPU_COUNT = torch.cuda.device_count()\n",
        "DEVICES = []\n",
        "\n",
        "# Se estamos no Kaggle mas n√£o detectou GPU, for√ßamos o modo GPU (normalmente 2 GPUs)\n",
        "if FORCE_GPU and GPU_COUNT == 0:\n",
        "    GPU_COUNT = 2\n",
        "    print(f\"üñ•Ô∏è Ambiente Kaggle detectado! For√ßando configura√ß√£o para {GPU_COUNT} GPUs\")\n",
        "    MAIN_DEVICE = torch.device('cuda:0')  # For√ßar como se tivesse GPU\n",
        "    for i in range(GPU_COUNT):\n",
        "        DEVICES.append(torch.device(f'cuda:{i}'))\n",
        "elif torch.cuda.is_available():\n",
        "    for i in range(GPU_COUNT):\n",
        "        DEVICES.append(torch.device(f'cuda:{i}'))\n",
        "    MAIN_DEVICE = torch.device('cuda:0')\n",
        "    print(f\"üñ•Ô∏è Usando {GPU_COUNT} GPUs:\")\n",
        "    for i in range(GPU_COUNT):\n",
        "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)} - {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
        "    torch.cuda.empty_cache()  # Limpar cache inicial\n",
        "else:\n",
        "    MAIN_DEVICE = torch.device('cpu')\n",
        "    DEVICES = [MAIN_DEVICE]\n",
        "    print(f\"‚ö†Ô∏è Nenhuma GPU detectada, usando CPU\")\n",
        "    print(f\"‚ÑπÔ∏è Lembre-se: este c√≥digo est√° otimizado para GPUs do Kaggle\")\n",
        "\n",
        "# Configura√ß√µes de paralelismo\n",
        "NUM_THREADS = min(16, os.cpu_count() * 2)  # Usar no m√°ximo 16 threads ou 2x CPU cores\n",
        "print(f\"üßµ Usando {NUM_THREADS} threads para opera√ß√µes paralelas\")\n",
        "\n",
        "# Configura√ß√µes do Puzzle 71 - Otimizado para Multi-GPU\n",
        "DEFAULT_BATCH_SIZE = 15000 if torch.cuda.is_available() else 1000\n",
        "DEFAULT_POPULATION_SIZE = 7500 if torch.cuda.is_available() else 500\n",
        "\n",
        "PUZZLE_71_CONFIG = {\n",
        "    'target_address': '1BGCfpwRDma3ViBsbQY5eZnRx8XcJpzSKV',\n",
        "    'bit_length': 71,\n",
        "    'min_range': 2**70,\n",
        "    'max_range': 2**71 - 1,\n",
        "    'batch_size': DEFAULT_BATCH_SIZE * max(1, GPU_COUNT),  # Escala com n√∫mero de GPUs\n",
        "    'population_size': DEFAULT_POPULATION_SIZE * max(1, GPU_COUNT)  # Escala com n√∫mero de GPUs\n",
        "}\n",
        "\n",
        "print(f\"Configura√ß√£o do Puzzle 71: {PUZZLE_71_CONFIG}\")\n",
        "print(f\"Espa√ßo de busca: 2^70 = {2**70:,} chaves poss√≠veis\")\n",
        "print(f\"Batch size aumentado para: {PUZZLE_71_CONFIG['batch_size']:,} (adaptado para {GPU_COUNT} GPUs)\")\n",
        "print(f\"Popula√ß√£o aumentada para: {PUZZLE_71_CONFIG['population_size']:,} (adaptada para {GPU_COUNT} GPUs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa88b5d",
      "metadata": {},
      "source": [
        "## Execu√ß√£o Multi-GPU - Instru√ß√µes para Kaggle\n",
        "\n",
        "Este notebook foi otimizado para usar m√∫ltiplas GPUs no ambiente Kaggle, mas pode apresentar problemas em alguns casos devido √† forma como o PyTorch gerencia dispositivos. Se voc√™ encontrar erros relacionados a dispositivos incompat√≠veis, considere:\n",
        "\n",
        "1. **Reiniciar o kernel**: √Äs vezes, um simples rein√≠cio do kernel resolve problemas de mem√≥ria GPU.\n",
        "\n",
        "2. **For√ßar dispositivo √∫nico**: Caso esteja tendo problemas com m√∫ltiplas GPUs, voc√™ pode for√ßar o uso de apenas uma GPU definindo:\n",
        "   ```python\n",
        "   GPU_COUNT = 1\n",
        "   DEVICES = [torch.device('cuda:0')]\n",
        "   ```\n",
        "\n",
        "3. **Se√ß√µes de execu√ß√£o**: Execute o notebook por partes, com as c√©lulas de configura√ß√£o primeiro seguidas pelas c√©lulas de execu√ß√£o.\n",
        "\n",
        "4. **Verificar disponibilidade**: Certifique-se que o Kaggle realmente disponibilizou as GPUs para sua sess√£o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ca5fba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 3: Utilit√°rios Bitcoin Otimizados para GPU\n",
        "class BitcoinUtils:\n",
        "    @staticmethod\n",
        "    def private_key_to_public_key_batch_gpu(private_keys_tensor, device_id=0):\n",
        "        \"\"\"Converte chaves privadas em p√∫blicas usando GPU com opera√ß√µes otimizadas\"\"\"\n",
        "        try:\n",
        "            # Selecionar dispositivo adequado para balanceamento de carga\n",
        "            device = torch.device(f'cuda:{device_id % GPU_COUNT}' if torch.cuda.is_available() else 'cpu')\n",
        "            \n",
        "            # Par√¢metros da curva secp256k1\n",
        "            p = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F\n",
        "            gx = 0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798\n",
        "            gy = 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8\n",
        "            \n",
        "            # Obter chaves privadas como valores inteiros\n",
        "            private_keys = []\n",
        "            batch_size = 0\n",
        "            \n",
        "            # Convertendo de diferentes formatos de entrada\n",
        "            if isinstance(private_keys_tensor, tuple):\n",
        "                # Caso seja uma tupla de tensores (formato dividido)\n",
        "                high_tensor, low_tensor = private_keys_tensor\n",
        "                batch_size = high_tensor.shape[0]\n",
        "                \n",
        "                # Dividir processamento em chunks para processamento paralelo\n",
        "                chunk_size = max(1, batch_size // GPU_COUNT)\n",
        "                all_keys = []\n",
        "                \n",
        "                # Processar em paralelo usando ThreadPoolExecutor\n",
        "                with ThreadPoolExecutor(max_workers=min(NUM_THREADS, batch_size)) as executor:\n",
        "                    futures = []\n",
        "                    \n",
        "                    for i in range(0, batch_size, chunk_size):\n",
        "                        end_idx = min(i + chunk_size, batch_size)\n",
        "                        futures.append(\n",
        "                            executor.submit(\n",
        "                                BitcoinUtils._process_key_chunk, \n",
        "                                high_tensor[i:end_idx], \n",
        "                                low_tensor[i:end_idx]\n",
        "                            )\n",
        "                        )\n",
        "                    \n",
        "                    # Coletar resultados\n",
        "                    for future in concurrent.futures.as_completed(futures):\n",
        "                        all_keys.extend(future.result())\n",
        "                    \n",
        "                private_keys = all_keys\n",
        "                    \n",
        "            elif private_keys_tensor.dtype == torch.float64:\n",
        "                # Caso seja um tensor de float64\n",
        "                batch_size = private_keys_tensor.shape[0]\n",
        "                private_keys = [int(private_keys_tensor[i].item()) for i in range(batch_size)]\n",
        "            else:\n",
        "                # Caso seja um tensor regular\n",
        "                batch_size = private_keys_tensor.shape[0]\n",
        "                private_keys = [int(private_keys_tensor[i].item()) for i in range(batch_size)]\n",
        "            \n",
        "            # Implementa√ß√£o otimizada para GPU \n",
        "            # Divide o batch para distribuir entre GPUs dispon√≠veis\n",
        "            public_keys = []\n",
        "            chunks = [private_keys[i:i + len(private_keys)//GPU_COUNT + 1] \n",
        "                     for i in range(0, len(private_keys), len(private_keys)//GPU_COUNT + 1)]\n",
        "            \n",
        "            with ThreadPoolExecutor(max_workers=GPU_COUNT) as executor:\n",
        "                futures = []\n",
        "                for i, chunk in enumerate(chunks):\n",
        "                    device_idx = i % GPU_COUNT\n",
        "                    futures.append(executor.submit(\n",
        "                        BitcoinUtils._compute_public_keys_on_gpu, \n",
        "                        chunk, p, gx, gy, device_idx\n",
        "                    ))\n",
        "                \n",
        "                for future in concurrent.futures.as_completed(futures):\n",
        "                    public_keys.extend(future.result())\n",
        "            \n",
        "            return public_keys\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na convers√£o GPU: {e}\")\n",
        "            logger.error(f\"Detalhes: {str(e)}\")\n",
        "            return []\n",
        "    \n",
        "    @staticmethod\n",
        "    def _process_key_chunk(high_chunk, low_chunk):\n",
        "        \"\"\"Processa um chunk de chaves (alta e baixa) e retorna as chaves reconstru√≠das\"\"\"\n",
        "        keys = []\n",
        "        for i in range(high_chunk.shape[0]):\n",
        "            high = high_chunk[i].item()\n",
        "            low = low_chunk[i].item()\n",
        "            key = high * (2**32) + low\n",
        "            keys.append(key)\n",
        "        return keys\n",
        "    \n",
        "    @staticmethod\n",
        "    def _compute_public_keys_on_gpu(private_keys_chunk, p, gx, gy, device_idx=0):\n",
        "        \"\"\"Calcular chaves p√∫blicas em GPU usando opera√ß√µes vetorizadas e otimizadas para PyTorch\"\"\"\n",
        "        device = torch.device(f'cuda:{device_idx}' if torch.cuda.is_available() else 'cpu')\n",
        "        results = []\n",
        "        \n",
        "        try:\n",
        "            # Otimiza√ß√£o: usar tamanho de lote adaptativo com base na mem√≥ria dispon√≠vel\n",
        "            if torch.cuda.is_available():\n",
        "                # Estimar mem√≥ria dispon√≠vel e ajustar batch size\n",
        "                gpu_mem = torch.cuda.get_device_properties(device).total_memory\n",
        "                used_mem = torch.cuda.memory_allocated(device)\n",
        "                # Usar no m√°ximo 80% da mem√≥ria dispon√≠vel\n",
        "                available_mem = (gpu_mem - used_mem) * 0.8\n",
        "                \n",
        "                # Estimar tamanho m√©dio por item (valores aproximados para matrizes e vetores)\n",
        "                # Principalmente para as opera√ß√µes de double precision\n",
        "                avg_item_size = 512  # bytes por item nas opera√ß√µes\n",
        "                \n",
        "                # Calcular batch size ideal\n",
        "                ideal_batch = int(available_mem / avg_item_size)\n",
        "                batch_size = min(5000, ideal_batch)  # M√°ximo 5000 para evitar problemas\n",
        "            else:\n",
        "                batch_size = 100  # Padr√£o menor para CPU\n",
        "            \n",
        "            # Processar em lotes otimizados\n",
        "            for start_idx in range(0, len(private_keys_chunk), batch_size):\n",
        "                end_idx = min(start_idx + batch_size, len(private_keys_chunk))\n",
        "                batch = private_keys_chunk[start_idx:end_idx]\n",
        "                \n",
        "                # Converter para tensor e mover para o device correto\n",
        "                keys_tensor = torch.tensor(batch, dtype=torch.float64, device=device)\n",
        "                \n",
        "                # Implementar multiplica√ß√£o escalar em lote usando fastecdsa (simulado em PyTorch)\n",
        "                # Em uma implementa√ß√£o real, chamaria uma biblioteca como fastecdsa ou um kernel CUDA personalizado\n",
        "                batch_results = BitcoinUtils._batch_ec_multiply(keys_tensor, p, gx, gy, device)\n",
        "                \n",
        "                # Processar resultados deste lote\n",
        "                for i in range(len(batch)):\n",
        "                    try:\n",
        "                        pub_x = int(batch_results[0][i].item())\n",
        "                        pub_y = int(batch_results[1][i].item())\n",
        "                        results.append((pub_x, pub_y))\n",
        "                    except Exception as e:\n",
        "                        logger.warning(f\"Erro ao processar resultado {i} no lote: {e}\")\n",
        "                        # Retornar valor nulo para este item\n",
        "                        results.append((0, 0))\n",
        "                \n",
        "                # Liberar mem√≥ria explicitamente\n",
        "                if torch.cuda.is_available():\n",
        "                    del keys_tensor, batch_results\n",
        "                    torch.cuda.empty_cache()\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro no processamento de lote em GPU {device_idx}: {e}\")\n",
        "            # Retornar resultados parciais ou vazios\n",
        "            if len(results) < len(private_keys_chunk):\n",
        "                # Preencher com valores nulos\n",
        "                results.extend([(0, 0)] * (len(private_keys_chunk) - len(results)))\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    @staticmethod\n",
        "    def _batch_ec_multiply(private_keys, p, gx, gy, device):\n",
        "        \"\"\"Multiplica√ß√£o escalar na curva el√≠ptica em lote usando PyTorch\n",
        "        \n",
        "        Nota: Em uma implementa√ß√£o real para produ√ß√£o, seria melhor usar uma biblioteca como\n",
        "        fastecdsa ou um kernel CUDA personalizado. Esta √© uma implementa√ß√£o educativa que\n",
        "        demonstra como usar PyTorch para opera√ß√µes vetorizadas na GPU.\n",
        "        \"\"\"\n",
        "        # Configura√ß√£o inicial de pontos e vari√°veis\n",
        "        batch_size = private_keys.shape[0]\n",
        "        \n",
        "        # Converter para representa√ß√£o PyTorch no dispositivo adequado\n",
        "        p_tensor = torch.tensor(p, dtype=torch.float64, device=device)\n",
        "        \n",
        "        # Inicializar tensores para os pontos resultantes\n",
        "        result_x = torch.zeros(batch_size, dtype=torch.float64, device=device)\n",
        "        result_y = torch.zeros(batch_size, dtype=torch.float64, device=device)\n",
        "        \n",
        "        # Para cada chave no batch, calculamos o resultado\n",
        "        # Em uma implementa√ß√£o vetorizada real, isto seria feito em paralelo\n",
        "        for i in range(batch_size):\n",
        "            k = private_keys[i].item()\n",
        "            \n",
        "            # Double and add algorithm para multiplica√ß√£o escalar\n",
        "            # Implementa√ß√£o simplificada para fins educativos\n",
        "            current_x = torch.tensor(gx, dtype=torch.float64, device=device)\n",
        "            current_y = torch.tensor(gy, dtype=torch.float64, device=device)\n",
        "            \n",
        "            # Para cada bit na representa√ß√£o bin√°ria da chave\n",
        "            for bit_pos in range(256):\n",
        "                if k & (1 << bit_pos):\n",
        "                    # Adicionar o ponto atual ao resultado\n",
        "                    if result_x == 0 and result_y == 0:\n",
        "                        result_x[i] = current_x\n",
        "                        result_y[i] = current_y\n",
        "                    else:\n",
        "                        # Adicionar pontos (implementa√ß√£o simplificada)\n",
        "                        # Numa implementa√ß√£o real, usaria f√≥rmulas completas da curva el√≠ptica\n",
        "                        temp_x, temp_y = BitcoinUtils._add_ec_points(\n",
        "                            result_x[i].item(), result_y[i].item(),\n",
        "                            current_x.item(), current_y.item(),\n",
        "                            p\n",
        "                        )\n",
        "                        result_x[i] = temp_x\n",
        "                        result_y[i] = temp_y\n",
        "                \n",
        "                # Duplicar o ponto atual (para o pr√≥ximo bit)\n",
        "                if bit_pos < 255:  # Evitar duplica√ß√£o desnecess√°ria na √∫ltima itera√ß√£o\n",
        "                    temp_x, temp_y = BitcoinUtils._double_ec_point(\n",
        "                        current_x.item(), current_y.item(), p\n",
        "                    )\n",
        "                    current_x = temp_x\n",
        "                    current_y = temp_y\n",
        "        \n",
        "        return result_x, result_y\n",
        "    \n",
        "    @staticmethod\n",
        "    def _add_ec_points(x1, y1, x2, y2, p):\n",
        "        \"\"\"Adiciona dois pontos na curva el√≠ptica (simplificado)\"\"\"\n",
        "        if x1 == 0 and y1 == 0:\n",
        "            return x2, y2\n",
        "        if x2 == 0 and y2 == 0:\n",
        "            return x1, y1\n",
        "        if x1 == x2 and y1 == (-y2 % p):\n",
        "            return 0, 0  # Ponto no infinito\n",
        "            \n",
        "        if x1 == x2 and y1 == y2:\n",
        "            return BitcoinUtils._double_ec_point(x1, y1, p)\n",
        "            \n",
        "        # Calcular inclina√ß√£o da reta\n",
        "        try:\n",
        "            numerator = (y2 - y1) % p\n",
        "            denominator = (x2 - x1) % p\n",
        "            # Inverso multiplicativo modular\n",
        "            denominator_inv = pow(denominator, p - 2, p)\n",
        "            slope = (numerator * denominator_inv) % p\n",
        "            \n",
        "            # Calcular novo ponto\n",
        "            x3 = (slope**2 - x1 - x2) % p\n",
        "            y3 = (slope * (x1 - x3) - y1) % p\n",
        "            \n",
        "            return x3, y3\n",
        "        except Exception as e:\n",
        "            # Se ocorrer erro, retornar ponto no infinito\n",
        "            return 0, 0\n",
        "    \n",
        "    @staticmethod\n",
        "    def _double_ec_point(x, y, p):\n",
        "        \"\"\"Duplica um ponto na curva el√≠ptica (simplificado)\"\"\"\n",
        "        if x == 0 and y == 0:\n",
        "            return 0, 0  # Ponto no infinito se o ponto original for infinito\n",
        "            \n",
        "        # Par√¢metro a da curva secp256k1 √© 0\n",
        "        a = 0\n",
        "        \n",
        "        try:\n",
        "            # Calcular inclina√ß√£o da reta tangente\n",
        "            numerator = (3 * x**2 + a) % p\n",
        "            denominator = (2 * y) % p\n",
        "            # Inverso multiplicativo modular\n",
        "            denominator_inv = pow(denominator, p - 2, p)\n",
        "            slope = (numerator * denominator_inv) % p\n",
        "            \n",
        "            # Calcular novo ponto\n",
        "            x3 = (slope**2 - 2*x) % p\n",
        "            y3 = (slope * (x - x3) - y) % p\n",
        "            \n",
        "            return x3, y3\n",
        "        except Exception as e:\n",
        "            # Se ocorrer erro, retornar ponto no infinito\n",
        "            return 0, 0\n",
        "\n",
        "    @staticmethod\n",
        "    def public_key_to_address(public_key):\n",
        "        \"\"\"Converte chave p√∫blica em endere√ßo Bitcoin\"\"\"\n",
        "        try:\n",
        "            pub_x, pub_y = public_key\n",
        "            \n",
        "            # Formato comprimido\n",
        "            if pub_y % 2 == 0:\n",
        "                compressed_pub = f\"02{pub_x:064x}\"\n",
        "            else:\n",
        "                compressed_pub = f\"03{pub_x:064x}\"\n",
        "            \n",
        "            # SHA256\n",
        "            pub_bytes = bytes.fromhex(compressed_pub)\n",
        "            sha256_hash = hashlib.sha256(pub_bytes).digest()\n",
        "            \n",
        "            # RIPEMD160\n",
        "            ripemd160 = hashlib.new('ripemd160')\n",
        "            ripemd160.update(sha256_hash)\n",
        "            hash160 = ripemd160.digest()\n",
        "            \n",
        "            # Adicionar byte de vers√£o (0x00 para mainnet)\n",
        "            versioned_hash = b'\\x00' + hash160\n",
        "            \n",
        "            # Checksum\n",
        "            checksum = hashlib.sha256(hashlib.sha256(versioned_hash).digest()).digest()[:4]\n",
        "            \n",
        "            # Base58 encoding\n",
        "            address_bytes = versioned_hash + checksum\n",
        "            \n",
        "            # Implementa√ß√£o simplificada do Base58\n",
        "            alphabet = \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\"\n",
        "            num = int.from_bytes(address_bytes, 'big')\n",
        "            address = \"\"\n",
        "            \n",
        "            while num > 0:\n",
        "                num, remainder = divmod(num, 58)\n",
        "                address = alphabet[remainder] + address\n",
        "            \n",
        "            # Adicionar zeros √† esquerda\n",
        "            for byte in address_bytes:\n",
        "                if byte == 0:\n",
        "                    address = '1' + address\n",
        "                else:\n",
        "                    break\n",
        "            \n",
        "            return address\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na convers√£o de endere√ßo: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def batch_addresses_check(public_keys, target_address, num_workers=None):\n",
        "        \"\"\"Verifica endere√ßos em paralelo\"\"\"\n",
        "        if num_workers is None:\n",
        "            num_workers = NUM_THREADS\n",
        "            \n",
        "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "            results = list(executor.map(\n",
        "                lambda pk: (BitcoinUtils.public_key_to_address(pk), pk), \n",
        "                public_keys\n",
        "            ))\n",
        "        \n",
        "        # Filtrar resultados\n",
        "        matches = []\n",
        "        for addr, pub_key in results:\n",
        "            if addr == target_address:\n",
        "                matches.append(pub_key)\n",
        "                \n",
        "        return matches, results\n",
        "\n",
        "print(\"BitcoinUtils carregado com otimiza√ß√µes multi-GPU avan√ßadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d33fc7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 2b: Verifica√ß√£o Manual de Dispositivos\n",
        "# Esta c√©lula √© opcional e pode ser executada para verificar ou ajustar dispositivos\n",
        "\n",
        "# Verificar dispositivos dispon√≠veis\n",
        "print(\"\\nüñ•Ô∏è Verifica√ß√£o de dispositivos:\\n\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPUs detectadas: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"   Mem√≥ria total: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
        "        print(f\"   Mem√≥ria alocada: {torch.cuda.memory_allocated(i) / 1e9:.1f} GB\")\n",
        "        print(f\"   Mem√≥ria reservada: {torch.cuda.memory_reserved(i) / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Nenhuma GPU dispon√≠vel, usando apenas CPU\")\n",
        "\n",
        "# Exibir configura√ß√£o atual\n",
        "print(f\"\\nConfigura√ß√µes atuais:\\nGPU_COUNT = {GPU_COUNT}\\nDEVICES = {DEVICES}\\nMAIN_DEVICE = {MAIN_DEVICE}\")\n",
        "\n",
        "# Op√ß√£o para ajustar manualmente (descomente para usar)\n",
        "# GPU_COUNT = 1  # For√ßar uso de apenas uma GPU \n",
        "# DEVICES = [torch.device('cuda:0')]  # Usar apenas a primeira GPU\n",
        "# MAIN_DEVICE = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a99c852",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 4: Gerador Inteligente de Chaves\n",
        "class SmartKeyGenerator:\n",
        "    def __init__(self, min_range, max_range, device='cpu'):\n",
        "        self.min_range = min_range\n",
        "        self.max_range = max_range\n",
        "        self.device = device\n",
        "        self.explored_regions = set()\n",
        "        # Constantes para divis√£o de n√∫meros grandes\n",
        "        self.SPLIT_VALUE = 2**32  # Usar para dividir o n√∫mero em partes alta e baixa\n",
        "        # Contador para balanceamento de carga entre GPUs\n",
        "        self.gpu_counter = 0\n",
        "        # Cache para valores Fibonacci para evitar rec√°lculo\n",
        "        self.fibonacci_cache = {0: 0, 1: 1}\n",
        "        # √öltimos valores de Fibonacci calculados (para otimiza√ß√£o)\n",
        "        self.last_fibonacci_values = []\n",
        "        self._precompute_fibonacci()\n",
        "        \n",
        "    def _precompute_fibonacci(self, limit=100):\n",
        "        \"\"\"Pr√©-calcular valores de Fibonacci para uso posterior\"\"\"\n",
        "        # Limpar cache anterior\n",
        "        self.last_fibonacci_values = []\n",
        "        \n",
        "        # Assegurar que os primeiros 2 valores existam\n",
        "        if 0 not in self.fibonacci_cache:\n",
        "            self.fibonacci_cache[0] = 0\n",
        "        if 1 not in self.fibonacci_cache:\n",
        "            self.fibonacci_cache[1] = 1\n",
        "        \n",
        "        # Pr√©-calcular valores at√© o limite\n",
        "        for i in range(2, limit+1):  # +1 para incluir o pr√≥prio limite\n",
        "            if i not in self.fibonacci_cache:\n",
        "                self.fibonacci_cache[i] = self.fibonacci_cache[i-1] + self.fibonacci_cache[i-2]\n",
        "            self.last_fibonacci_values.append(self.fibonacci_cache[i])\n",
        "            \n",
        "        # Adicionar valores mais pr√≥ximos do range de busca\n",
        "        n = limit\n",
        "        \n",
        "        # Verificar se n j√° est√° no cache (n√£o deveria ser necess√°rio, mas por seguran√ßa)\n",
        "        if n not in self.fibonacci_cache:\n",
        "            self.fibonacci_cache[n] = self.fibonacci_cache[n-1] + self.fibonacci_cache[n-2]\n",
        "            \n",
        "        while self.fibonacci_cache[n] < self.max_range:\n",
        "            n += 1\n",
        "            self.fibonacci_cache[n] = self.fibonacci_cache[n-1] + self.fibonacci_cache[n-2]\n",
        "            self.last_fibonacci_values.append(self.fibonacci_cache[n])\n",
        "            \n",
        "            # Limitar o n√∫mero de valores calculados\n",
        "            if len(self.last_fibonacci_values) > 200:\n",
        "                # Manter apenas os 100 valores mais altos\n",
        "                self.last_fibonacci_values = self.last_fibonacci_values[-100:]\n",
        "    \n",
        "    def get_next_device(self):\n",
        "        \"\"\"Retorna o pr√≥ximo dispositivo para balanceamento de carga\"\"\"\n",
        "        if not torch.cuda.is_available() or GPU_COUNT == 0 or not DEVICES:\n",
        "            return MAIN_DEVICE\n",
        "            \n",
        "        try:\n",
        "            device = DEVICES[self.gpu_counter % len(DEVICES)]\n",
        "            self.gpu_counter = (self.gpu_counter + 1) % len(DEVICES)\n",
        "            return device\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Erro ao obter dispositivo: {e}. Usando dispositivo principal.\")\n",
        "            return MAIN_DEVICE\n",
        "        \n",
        "    def generate_smart_batch(self, batch_size, strategy='adaptive'):\n",
        "        \"\"\"Gera lote de chaves com estrat√©gia inteligente\"\"\"\n",
        "        if strategy == 'adaptive':\n",
        "            return self._adaptive_strategy(batch_size)\n",
        "        elif strategy == 'fibonacci':\n",
        "            return self._fibonacci_strategy(batch_size)\n",
        "        elif strategy == 'quantum_inspired':\n",
        "            return self._quantum_inspired_strategy(batch_size)\n",
        "        else:\n",
        "            return self._random_strategy(batch_size)\n",
        "    \n",
        "    def generate_smart_multi_batch(self, batch_size, strategies=None):\n",
        "        \"\"\"Gera lotes paralelos usando m√∫ltiplas estrat√©gias em m√∫ltiplas GPUs\"\"\"\n",
        "        if strategies is None:\n",
        "            strategies = ['adaptive', 'fibonacci', 'quantum_inspired', 'random']\n",
        "            \n",
        "        results = []\n",
        "        batch_per_strategy = batch_size // len(strategies)\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=min(len(strategies), GPU_COUNT)) as executor:\n",
        "            futures = []\n",
        "            \n",
        "            for strategy in strategies:\n",
        "                futures.append(executor.submit(\n",
        "                    self._generate_strategy_batch,\n",
        "                    strategy,\n",
        "                    batch_per_strategy\n",
        "                ))\n",
        "                \n",
        "            # Coletar resultados\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                results.append(future.result())\n",
        "                \n",
        "        # Combinar resultados de todas as estrat√©gias\n",
        "        # Primeiro mover todos os tensores para o mesmo dispositivo (MAIN_DEVICE)\n",
        "        moved_results = []\n",
        "        for high_tensor, low_tensor in results:\n",
        "            moved_results.append((\n",
        "                high_tensor.to(MAIN_DEVICE),\n",
        "                low_tensor.to(MAIN_DEVICE)\n",
        "            ))\n",
        "        \n",
        "        # Agora fazer a concatena√ß√£o com tensores no mesmo dispositivo\n",
        "        combined_high = torch.cat([r[0] for r in moved_results], dim=0)\n",
        "        combined_low = torch.cat([r[1] for r in moved_results], dim=0)\n",
        "        \n",
        "        # Garantir o tamanho exato do batch\n",
        "        return combined_high[:batch_size], combined_low[:batch_size]\n",
        "    \n",
        "    def _generate_strategy_batch(self, strategy, batch_size):\n",
        "        \"\"\"Helper para gerar lotes em paralelo\"\"\"\n",
        "        try:\n",
        "            device = self.get_next_device()\n",
        "            \n",
        "            if strategy == 'adaptive':\n",
        "                keys = self._adaptive_strategy_core(batch_size)\n",
        "            elif strategy == 'fibonacci':\n",
        "                keys = self._fibonacci_strategy_core(batch_size)\n",
        "            elif strategy == 'quantum_inspired':\n",
        "                keys = self._quantum_inspired_strategy_core(batch_size)\n",
        "            else:\n",
        "                keys = self._random_strategy_core(batch_size)\n",
        "                \n",
        "            # Converter para tensores no dispositivo correto\n",
        "            try:\n",
        "                return self._keys_to_tensor(keys, device)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Erro ao converter tensores para dispositivo {device}: {e}\")\n",
        "                # Tentar com o dispositivo principal como fallback\n",
        "                return self._keys_to_tensor(keys, MAIN_DEVICE)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na gera√ß√£o de lote: {e}\")\n",
        "            # Gerar lote aleat√≥rio como fallback\n",
        "            fallback_keys = [random.randint(self.min_range, self.max_range) for _ in range(batch_size)]\n",
        "            return self._keys_to_tensor(fallback_keys, MAIN_DEVICE)\n",
        "    \n",
        "    def _adaptive_strategy(self, batch_size):\n",
        "        \"\"\"Estrat√©gia adaptativa baseada em padr√µes\"\"\"\n",
        "        keys = self._adaptive_strategy_core(batch_size)\n",
        "        # Converter em formato seguro para tensores\n",
        "        return self._keys_to_tensor(keys, self.device)\n",
        "    \n",
        "    def _adaptive_strategy_core(self, batch_size):\n",
        "        \"\"\"N√∫cleo da estrat√©gia adaptativa (apenas gera√ß√£o de chaves sem convers√£o para tensor)\"\"\"\n",
        "        keys = []\n",
        "        \n",
        "        # 40% pr√≥ximo ao meio do range\n",
        "        mid_point = (self.min_range + self.max_range) // 2\n",
        "        mid_keys = int(batch_size * 0.4)\n",
        "        for _ in range(mid_keys):\n",
        "            offset = random.randint(-2**35, 2**35)\n",
        "            key = max(self.min_range, min(self.max_range, mid_point + offset))\n",
        "            keys.append(key)\n",
        "        \n",
        "        # 30% em pontos de interesse (m√∫ltiplos de n√∫meros especiais)\n",
        "        special_keys = int(batch_size * 0.3)\n",
        "        special_numbers = [7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n",
        "        for _ in range(special_keys):\n",
        "            base = random.choice(special_numbers)\n",
        "            multiplier = random.randint(self.min_range // base, self.max_range // base)\n",
        "            key = base * multiplier\n",
        "            if self.min_range <= key <= self.max_range:\n",
        "                keys.append(key)\n",
        "        \n",
        "        # 30% completamente aleat√≥rio\n",
        "        random_keys = batch_size - len(keys)\n",
        "        for _ in range(random_keys):\n",
        "            key = random.randint(self.min_range, self.max_range)\n",
        "            keys.append(key)\n",
        "            \n",
        "        return keys\n",
        "    \n",
        "    def _fibonacci_strategy(self, batch_size):\n",
        "        \"\"\"Estrat√©gia baseada em sequ√™ncia de Fibonacci\"\"\"\n",
        "        keys = self._fibonacci_strategy_core(batch_size)\n",
        "        # Converter em formato seguro para tensores\n",
        "        return self._keys_to_tensor(keys, self.device)\n",
        "    \n",
        "    def _fibonacci_strategy_core(self, batch_size):\n",
        "        \"\"\"N√∫cleo da estrat√©gia de Fibonacci otimizada (apenas gera√ß√£o de chaves)\"\"\"\n",
        "        keys = []\n",
        "        \n",
        "        # Verificar se o cache de fibonacci tem valores suficientes\n",
        "        if len(self.last_fibonacci_values) < 50:\n",
        "            self._precompute_fibonacci(100)\n",
        "            \n",
        "        # Usar os valores de fibonacci para criar padr√µes de chaves\n",
        "        for _ in range(batch_size):\n",
        "            strategy = random.randint(1, 4)\n",
        "            \n",
        "            if strategy == 1:  # 25% - baseado em m√∫ltiplos de fibonacci\n",
        "                fib_value = random.choice(self.last_fibonacci_values)\n",
        "                multiplier = random.randint(1, 10000)\n",
        "                key = (fib_value * multiplier) % (self.max_range + 1)\n",
        "                \n",
        "                # Garantir que esteja no range v√°lido\n",
        "                if key < self.min_range:\n",
        "                    key += self.min_range\n",
        "                if key > self.max_range:\n",
        "                    key = self.min_range + (key % (self.max_range - self.min_range))\n",
        "                    \n",
        "            elif strategy == 2:  # 25% - combina√ß√µes de fibonacci\n",
        "                # Combinar dois n√∫meros de fibonacci diferentes\n",
        "                fib1 = random.choice(self.last_fibonacci_values)\n",
        "                fib2 = random.choice(self.last_fibonacci_values)\n",
        "                key = (fib1 + fib2) % (self.max_range + 1)\n",
        "                \n",
        "                # Garantir que esteja no range v√°lido\n",
        "                if key < self.min_range:\n",
        "                    key += self.min_range\n",
        "                if key > self.max_range:\n",
        "                    key = self.min_range + (key % (self.max_range - self.min_range))\n",
        "                    \n",
        "            elif strategy == 3:  # 25% - chaves pr√≥ximas a fibonacci\n",
        "                fib_value = random.choice(self.last_fibonacci_values)\n",
        "                # Adicionar/subtrair um valor aleat√≥rio pequeno\n",
        "                offset = random.randint(-1000000, 1000000)\n",
        "                key = fib_value + offset\n",
        "                \n",
        "                # Garantir que esteja no range v√°lido\n",
        "                if key < self.min_range:\n",
        "                    key = self.min_range + (key % (self.max_range - self.min_range))\n",
        "                if key > self.max_range:\n",
        "                    key = self.max_range - (key % (self.max_range - self.min_range))\n",
        "                    \n",
        "            else:  # 25% - completamente aleat√≥rio no range\n",
        "                key = random.randint(self.min_range, self.max_range)\n",
        "            \n",
        "            # Adicionar chave se estiver no range v√°lido\n",
        "            if self.min_range <= key <= self.max_range:\n",
        "                keys.append(key)\n",
        "            else:\n",
        "                # Se por algum motivo a chave estiver fora do range, gerar uma aleat√≥ria\n",
        "                keys.append(random.randint(self.min_range, self.max_range))\n",
        "        \n",
        "        return keys\n",
        "    \n",
        "    def _quantum_inspired_strategy(self, batch_size):\n",
        "        \"\"\"Estrat√©gia inspirada em conceitos qu√¢nticos (sobreposi√ß√£o de estados)\"\"\"\n",
        "        keys = self._quantum_inspired_strategy_core(batch_size)\n",
        "        return self._keys_to_tensor(keys, self.device)\n",
        "    \n",
        "    def _quantum_inspired_strategy_core(self, batch_size):\n",
        "        \"\"\"N√∫cleo da estrat√©gia inspirada em conceitos qu√¢nticos\"\"\"\n",
        "        keys = []\n",
        "        \n",
        "        # Definir n√∫mero de estados (simula√ß√£o qu√¢ntica)\n",
        "        num_states = min(8, batch_size // 10 + 1)  # No m√°ximo 8 estados\n",
        "        \n",
        "        # Gerar estados base (pontos de refer√™ncia no espa√ßo de chaves)\n",
        "        base_states = []\n",
        "        for _ in range(num_states):\n",
        "            state_type = random.randint(1, 4)\n",
        "            \n",
        "            if state_type == 1:\n",
        "                # Estado baseado no meio do range\n",
        "                base_states.append((self.min_range + self.max_range) // 2)\n",
        "            elif state_type == 2:\n",
        "                # Estado baseado em n√∫mero de Fibonacci\n",
        "                if self.last_fibonacci_values:\n",
        "                    base_states.append(random.choice(self.last_fibonacci_values) % self.max_range)\n",
        "                else:\n",
        "                    base_states.append(random.randint(self.min_range, self.max_range))\n",
        "            elif state_type == 3:\n",
        "                # Estado baseado em pontos especiais\n",
        "                special_base = random.choice([7, 11, 13, 17, 19, 23, 29, 31]) * 10**9\n",
        "                base_states.append(max(self.min_range, min(self.max_range, special_base)))\n",
        "            else:\n",
        "                # Estado aleat√≥rio\n",
        "                base_states.append(random.randint(self.min_range, self.max_range))\n",
        "        \n",
        "        # Gerar chaves como \"superposi√ß√µes\" dos estados base\n",
        "        for _ in range(batch_size):\n",
        "            # Simular medidas de estados qu√¢nticos\n",
        "            # Escolher dois estados aleat√≥rios e cria uma \"superposi√ß√£o\"\n",
        "            state1 = random.choice(base_states)\n",
        "            state2 = random.choice(base_states)\n",
        "            \n",
        "            # \"Interferir\" os estados com pesos aleat√≥rios\n",
        "            weight1 = random.random()\n",
        "            weight2 = 1 - weight1\n",
        "            \n",
        "            # Criar \"superposi√ß√£o\" (combina√ß√£o linear)\n",
        "            combined_state = int(weight1 * state1 + weight2 * state2)\n",
        "            \n",
        "            # Adicionar \"ru√≠do qu√¢ntico\" (pequena perturba√ß√£o aleat√≥ria)\n",
        "            noise = random.randint(-2**24, 2**24)\n",
        "            key = combined_state + noise\n",
        "            \n",
        "            # Garantir que est√° no range v√°lido\n",
        "            key = max(self.min_range, min(self.max_range, key))\n",
        "            keys.append(key)\n",
        "        \n",
        "        return keys\n",
        "    \n",
        "    def _random_strategy(self, batch_size):\n",
        "        \"\"\"Estrat√©gia puramente aleat√≥ria\"\"\"\n",
        "        keys = self._random_strategy_core(batch_size)\n",
        "        return self._keys_to_tensor(keys, self.device)\n",
        "    \n",
        "    def _random_strategy_core(self, batch_size):\n",
        "        \"\"\"N√∫cleo da estrat√©gia aleat√≥ria\"\"\"\n",
        "        return [random.randint(self.min_range, self.max_range) for _ in range(batch_size)]\n",
        "    \n",
        "    def _keys_to_tensor(self, keys, device):\n",
        "        \"\"\"Converte lista de chaves em tuplas de tensores (high, low) para evitar overflow\"\"\"\n",
        "        high_parts = []\n",
        "        low_parts = []\n",
        "        \n",
        "        for key in keys:\n",
        "            # Dividir em parte alta e baixa\n",
        "            high = key // self.SPLIT_VALUE\n",
        "            low = key % self.SPLIT_VALUE\n",
        "            high_parts.append(high)\n",
        "            low_parts.append(low)\n",
        "        \n",
        "        # Criar tensores para cada parte\n",
        "        high_tensor = torch.tensor(high_parts, dtype=torch.int64, device=device)\n",
        "        low_tensor = torch.tensor(low_parts, dtype=torch.int64, device=device)\n",
        "        \n",
        "        return high_tensor, low_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ed7ae8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 5: Algoritmo Gen√©tico Otimizado para Multi-GPU\n",
        "class GeneticAlgorithm:\n",
        "    def __init__(self, population_size, mutation_rate=0.1, crossover_rate=0.8, device='cpu'):\n",
        "        self.population_size = population_size\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.main_device = device\n",
        "        self.population = None  # Agora ser√° uma tupla de tensores (high, low)\n",
        "        self.fitness_scores = None\n",
        "        self.generation = 0\n",
        "        # Constante para divis√£o de n√∫meros grandes\n",
        "        self.SPLIT_VALUE = 2**32\n",
        "        # Contador para balanceamento de carga entre GPUs\n",
        "        self.gpu_counter = 0\n",
        "        \n",
        "    def get_next_device(self):\n",
        "        \"\"\"Retorna o pr√≥ximo dispositivo para balanceamento de carga\"\"\"\n",
        "        if not torch.cuda.is_available() or GPU_COUNT == 0 or not DEVICES:\n",
        "            return MAIN_DEVICE\n",
        "            \n",
        "        try:\n",
        "            device = DEVICES[self.gpu_counter % len(DEVICES)]\n",
        "            self.gpu_counter = (self.gpu_counter + 1) % len(DEVICES)\n",
        "            return device\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Erro ao obter dispositivo: {e}. Usando dispositivo principal.\")\n",
        "            return MAIN_DEVICE\n",
        "        \n",
        "    def initialize_population(self, min_range, max_range):\n",
        "        \"\"\"Inicializa popula√ß√£o com diversidade\"\"\"\n",
        "        # Se temos GPU, vamos distribuir a popula√ß√£o entre as GPUs\n",
        "        if GPU_COUNT > 1 and torch.cuda.is_available():\n",
        "            return self._initialize_multi_gpu_population(min_range, max_range)\n",
        "        else:\n",
        "            return self._initialize_single_population(min_range, max_range)\n",
        "            \n",
        "    def _initialize_single_population(self, min_range, max_range):\n",
        "        \"\"\"Inicializa popula√ß√£o em um √∫nico dispositivo\"\"\"\n",
        "        population = []\n",
        "        \n",
        "        # 50% aleat√≥rio uniforme\n",
        "        for _ in range(self.population_size // 2):\n",
        "            key = random.randint(min_range, max_range)\n",
        "            population.append(key)\n",
        "        \n",
        "        # 25% concentrado no meio\n",
        "        mid_point = (min_range + max_range) // 2\n",
        "        for _ in range(self.population_size // 4):\n",
        "            offset = random.randint(-2**35, 2**35)\n",
        "            key = max(min_range, min(max_range, mid_point + offset))\n",
        "            population.append(key)\n",
        "        \n",
        "        # 25% em extremos\n",
        "        for _ in range(self.population_size - len(population)):\n",
        "            if random.random() < 0.5:\n",
        "                key = random.randint(min_range, min_range + 2**35)\n",
        "            else:\n",
        "                key = random.randint(max_range - 2**35, max_range)\n",
        "            population.append(key)\n",
        "        \n",
        "        # Converter para representa√ß√£o segura\n",
        "        self.population = self._keys_to_tensor(population, self.main_device)\n",
        "        self.fitness_scores = torch.zeros(self.population_size, device=self.main_device)\n",
        "        \n",
        "        return self.population\n",
        "        \n",
        "    def _initialize_multi_gpu_population(self, min_range, max_range):\n",
        "        \"\"\"Inicializa popula√ß√£o dividida entre m√∫ltiplas GPUs\"\"\"\n",
        "        futures = []\n",
        "        pop_per_gpu = self.population_size // GPU_COUNT\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=GPU_COUNT) as executor:\n",
        "            for i in range(GPU_COUNT):\n",
        "                try:\n",
        "                    device = torch.device(f'cuda:{i}')\n",
        "                    futures.append(executor.submit(\n",
        "                        self._generate_subpopulation, \n",
        "                        min_range, \n",
        "                        max_range, \n",
        "                        pop_per_gpu,\n",
        "                        device\n",
        "                    ))\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Erro ao configurar dispositivo cuda:{i}: {e}\")\n",
        "                    # Tentar usar CPU como fallback\n",
        "                    futures.append(executor.submit(\n",
        "                        self._generate_subpopulation, \n",
        "                        min_range, \n",
        "                        max_range, \n",
        "                        pop_per_gpu,\n",
        "                        MAIN_DEVICE\n",
        "                    ))\n",
        "                \n",
        "        # Coletar resultados\n",
        "        high_tensors = []\n",
        "        low_tensors = []\n",
        "        \n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            h, l = future.result()\n",
        "            high_tensors.append(h)\n",
        "            low_tensors.append(l)            # Combinar popula√ß√µes das diferentes GPUs\n",
        "            if GPU_COUNT > 0:\n",
        "                # Verificar se h√° tensores v√°lidos\n",
        "                if high_tensors and low_tensors:\n",
        "                    # Mover todos os tensores para o mesmo dispositivo antes de concatenar\n",
        "                    high_tensors_same_device = [h.to(self.main_device) for h in high_tensors]\n",
        "                    low_tensors_same_device = [l.to(self.main_device) for l in low_tensors]\n",
        "                    \n",
        "                    # Concatenar tensores no mesmo dispositivo\n",
        "                    combined_high = torch.cat(high_tensors_same_device, dim=0)\n",
        "                    combined_low = torch.cat(low_tensors_same_device, dim=0)\n",
        "                    \n",
        "                    # Garantir o tamanho exato da popula√ß√£o\n",
        "                    self.population = (\n",
        "                        combined_high[:self.population_size], \n",
        "                        combined_low[:self.population_size]\n",
        "                    )\n",
        "                else:\n",
        "                    logger.warning(\"N√£o foram gerados tensores suficientes nas GPUs\")\n",
        "            self.fitness_scores = torch.zeros(self.population_size, device=self.main_device)\n",
        "            \n",
        "            return self.population\n",
        "        else:\n",
        "            # Fallback para single device\n",
        "            return self._initialize_single_population(min_range, max_range)\n",
        "            \n",
        "    def _generate_subpopulation(self, min_range, max_range, pop_size, device):\n",
        "        \"\"\"Gera uma parte da popula√ß√£o em um dispositivo espec√≠fico\"\"\"\n",
        "        population = []\n",
        "        \n",
        "        # 50% aleat√≥rio uniforme\n",
        "        for _ in range(pop_size // 2):\n",
        "            key = random.randint(min_range, max_range)\n",
        "            population.append(key)\n",
        "        \n",
        "        # 25% concentrado no meio\n",
        "        mid_point = (min_range + max_range) // 2\n",
        "        for _ in range(pop_size // 4):\n",
        "            offset = random.randint(-2**35, 2**35)\n",
        "            key = max(min_range, min(max_range, mid_point + offset))\n",
        "            population.append(key)\n",
        "        \n",
        "        # 25% em extremos\n",
        "        for _ in range(pop_size - len(population)):\n",
        "            if random.random() < 0.5:\n",
        "                key = random.randint(min_range, min_range + 2**35)\n",
        "            else:\n",
        "                key = random.randint(max_range - 2**35, max_range)\n",
        "            population.append(key)\n",
        "            \n",
        "        # Converter para tensores\n",
        "        return self._keys_to_tensor(population, device)\n",
        "    \n",
        "    def _keys_to_tensor(self, keys, device):\n",
        "        \"\"\"Converte lista de chaves grandes em tupla de tensores (high, low)\"\"\"\n",
        "        high_parts = []\n",
        "        low_parts = []\n",
        "        \n",
        "        for key in keys:\n",
        "            # Dividir em parte alta e baixa para evitar overflow\n",
        "            high = key // self.SPLIT_VALUE\n",
        "            low = key % self.SPLIT_VALUE\n",
        "            high_parts.append(high)\n",
        "            low_parts.append(low)\n",
        "        \n",
        "        # Criar tensores separados para partes alta e baixa\n",
        "        high_tensor = torch.tensor(high_parts, dtype=torch.int64, device=device)\n",
        "        low_tensor = torch.tensor(low_parts, dtype=torch.int64, device=device)\n",
        "        \n",
        "        # Retornar como uma tupla de tensores\n",
        "        return (high_tensor, low_tensor)\n",
        "    \n",
        "    def _tensor_to_keys(self, tensor_pair):\n",
        "        \"\"\"Converte tensores de volta para valores inteiros\"\"\"\n",
        "        high_tensor, low_tensor = tensor_pair\n",
        "        keys = []\n",
        "        \n",
        "        for i in range(high_tensor.shape[0]):\n",
        "            high = high_tensor[i].item()\n",
        "            low = low_tensor[i].item()\n",
        "            key = high * self.SPLIT_VALUE + low\n",
        "            keys.append(key)\n",
        "        \n",
        "        return keys\n",
        "    \n",
        "    def evaluate_fitness_batch(self, target_address):\n",
        "        \"\"\"Avalia fitness de toda a popula√ß√£o\"\"\"\n",
        "        try:\n",
        "            # Se temos m√∫ltiplas GPUs, vamos dividir a popula√ß√£o para avalia√ß√£o\n",
        "            if GPU_COUNT > 1 and torch.cuda.is_available():\n",
        "                return self._evaluate_fitness_multi_gpu(target_address)\n",
        "            else:\n",
        "                return self._evaluate_fitness_single_device(target_address)\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na avalia√ß√£o de fitness: {e}\")\n",
        "            return torch.zeros(self.population_size, device=self.main_device)\n",
        "            \n",
        "    def _evaluate_fitness_single_device(self, target_address):\n",
        "        \"\"\"Avalia fitness em um √∫nico dispositivo\"\"\"\n",
        "        try:\n",
        "            # Converter tensores para lista de chaves\n",
        "            keys = self._tensor_to_keys(self.population)\n",
        "            \n",
        "            # Criar tensor tempor√°rio para processar chaves p√∫blicas\n",
        "            # (usando valor √∫nico para processamento em lote)\n",
        "            temp_tensor = torch.tensor(keys, dtype=torch.float64, device=self.main_device)\n",
        "            \n",
        "            # Gerar chaves p√∫blicas em lote\n",
        "            public_keys = BitcoinUtils.private_key_to_public_key_batch_gpu(temp_tensor)\n",
        "            \n",
        "            # Avaliar fitness (dist√¢ncia do endere√ßo alvo)\n",
        "            fitness_scores = []\n",
        "            \n",
        "            # Paralelizar verifica√ß√£o de endere√ßos\n",
        "            matches, results = BitcoinUtils.batch_addresses_check(public_keys, target_address)\n",
        "            \n",
        "            # Se encontramos correspond√™ncias\n",
        "            if matches:\n",
        "                for i, (addr, pub_key) in enumerate(results):\n",
        "                    if addr == target_address:\n",
        "                        fitness_scores.append(1000000.0)  # Solu√ß√£o encontrada!\n",
        "                        logger.info(f\"üéâ CHAVE ENCONTRADA! {keys[i]}\")\n",
        "                    else:\n",
        "                        similarity = self._calculate_address_similarity(addr, target_address)\n",
        "                        fitness_scores.append(similarity)\n",
        "            else:\n",
        "                # Processar resultados\n",
        "                for addr, _ in results:\n",
        "                    if addr:\n",
        "                        similarity = self._calculate_address_similarity(addr, target_address)\n",
        "                        fitness_scores.append(similarity)\n",
        "                    else:\n",
        "                        fitness_scores.append(0.0)\n",
        "            \n",
        "            self.fitness_scores = torch.tensor(fitness_scores, device=self.main_device)\n",
        "            return self.fitness_scores\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na avalia√ß√£o de fitness (single): {e}\")\n",
        "            return torch.zeros(self.population_size, device=self.main_device)\n",
        "            \n",
        "    def _evaluate_fitness_multi_gpu(self, target_address):\n",
        "        \"\"\"Avalia fitness dividindo o trabalho entre m√∫ltiplas GPUs\"\"\"\n",
        "        try:\n",
        "            # Converter tensores para lista de chaves\n",
        "            keys = self._tensor_to_keys(self.population)\n",
        "            \n",
        "            # Dividir chaves entre as GPUs\n",
        "            chunk_size = len(keys) // GPU_COUNT + 1\n",
        "            chunks = [keys[i:i+chunk_size] for i in range(0, len(keys), chunk_size)]\n",
        "            \n",
        "            # Avaliar cada chunk em paralelo em uma GPU separada\n",
        "            futures = []\n",
        "            \n",
        "            with ThreadPoolExecutor(max_workers=GPU_COUNT) as executor:\n",
        "                for i, chunk in enumerate(chunks):\n",
        "                    futures.append(executor.submit(\n",
        "                        self._evaluate_chunk_fitness,\n",
        "                        chunk,\n",
        "                        target_address,\n",
        "                        i % GPU_COUNT\n",
        "                    ))\n",
        "            \n",
        "            # Combinar resultados\n",
        "            all_fitness = []\n",
        "            solution_found = False\n",
        "            solution_key = None\n",
        "            \n",
        "            for i, future in enumerate(futures):\n",
        "                chunk_fitness, found_key = future.result()\n",
        "                \n",
        "                if found_key:\n",
        "                    solution_found = True\n",
        "                    solution_key = found_key\n",
        "                    \n",
        "                # Adicionar √† lista completa de fitness\n",
        "                offset = i * chunk_size\n",
        "                for j, score in enumerate(chunk_fitness):\n",
        "                    if offset + j < len(keys):  # Proteger contra √≠ndice fora de alcance\n",
        "                        all_fitness.append(score)\n",
        "            \n",
        "            # Se encontrou solu√ß√£o, ajustar pontua√ß√£o de fitness\n",
        "            if solution_found:\n",
        "                # Encontrar √≠ndice da chave na popula√ß√£o original\n",
        "                for i, key in enumerate(keys):\n",
        "                    if key == solution_key:\n",
        "                        all_fitness[i] = 1000000.0  # Marcar como solu√ß√£o encontrada\n",
        "                        break\n",
        "                        \n",
        "            # Converter resultados para tensor\n",
        "            self.fitness_scores = torch.tensor(all_fitness, device=self.main_device)\n",
        "            return self.fitness_scores\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na avalia√ß√£o de fitness (multi-GPU): {e}\")\n",
        "            return torch.zeros(self.population_size, device=self.main_device)\n",
        "            \n",
        "    def _evaluate_chunk_fitness(self, key_chunk, target_address, device_idx):\n",
        "        \"\"\"Avalia fitness de um chunk de chaves em uma GPU espec√≠fica\"\"\"\n",
        "        device = torch.device(f'cuda:{device_idx}' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        try:\n",
        "            temp_tensor = torch.tensor(key_chunk, dtype=torch.float64, device=device)\n",
        "            \n",
        "            # Gerar chaves p√∫blicas\n",
        "            public_keys = BitcoinUtils.private_key_to_public_key_batch_gpu(temp_tensor, device_idx)\n",
        "            \n",
        "            # Avaliar fitness\n",
        "            fitness_scores = []\n",
        "            found_key = None\n",
        "            \n",
        "            for i, pub_key in enumerate(public_keys):\n",
        "                if pub_key:\n",
        "                    address = BitcoinUtils.public_key_to_address(pub_key)\n",
        "                    \n",
        "                    if address == target_address:\n",
        "                        fitness_scores.append(1000000.0)  # Solu√ß√£o encontrada!\n",
        "                        found_key = key_chunk[i]\n",
        "                        logger.info(f\"üéâ CHAVE ENCONTRADA (GPU {device_idx})! {found_key}\")\n",
        "                    else:\n",
        "                        similarity = self._calculate_address_similarity(address, target_address)\n",
        "                        fitness_scores.append(similarity)\n",
        "                else:\n",
        "                    fitness_scores.append(0.0)\n",
        "                    \n",
        "            return fitness_scores, found_key\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na avalia√ß√£o de chunk (GPU {device_idx}): {e}\")\n",
        "            return [0.0] * len(key_chunk), None\n",
        "    \n",
        "    def _calculate_address_similarity(self, addr1, addr2):\n",
        "        \"\"\"Calcula similaridade entre endere√ßos\"\"\"\n",
        "        if not addr1 or not addr2:\n",
        "            return 0.0\n",
        "        \n",
        "        # Comparar caracteres\n",
        "        matches = sum(1 for a, b in zip(addr1, addr2) if a == b)\n",
        "        return matches / max(len(addr1), len(addr2))\n",
        "    \n",
        "    def selection(self, tournament_size=5):\n",
        "        \"\"\"Sele√ß√£o por torneio\"\"\"\n",
        "        selected_high = []\n",
        "        selected_low = []\n",
        "        high_tensor, low_tensor = self.population\n",
        "        \n",
        "        for _ in range(self.population_size):\n",
        "            tournament_indices = torch.randint(0, self.population_size, (tournament_size,), device=self.main_device)\n",
        "            tournament_fitness = self.fitness_scores[tournament_indices]\n",
        "            winner_idx = tournament_indices[torch.argmax(tournament_fitness)]\n",
        "            selected_high.append(high_tensor[winner_idx].item())\n",
        "            selected_low.append(low_tensor[winner_idx].item())\n",
        "        \n",
        "        return (torch.tensor(selected_high, dtype=torch.int64, device=self.main_device),\n",
        "                torch.tensor(selected_low, dtype=torch.int64, device=self.main_device))\n",
        "    \n",
        "    def crossover(self, parent1_high, parent1_low, parent2_high, parent2_low):\n",
        "        \"\"\"Crossover aritm√©tico adaptado para representa√ß√£o em duas partes\"\"\"\n",
        "        # Reconstruir os valores completos\n",
        "        parent1 = parent1_high * self.SPLIT_VALUE + parent1_low\n",
        "        parent2 = parent2_high * self.SPLIT_VALUE + parent2_low\n",
        "        \n",
        "        if random.random() > self.crossover_rate:\n",
        "            child1, child2 = parent1, parent2\n",
        "        else:\n",
        "            alpha = random.random()\n",
        "            child1 = int(alpha * parent1 + (1 - alpha) * parent2)\n",
        "            child2 = int((1 - alpha) * parent1 + alpha * parent2)\n",
        "        \n",
        "        # Dividir os resultados novamente\n",
        "        child1_high = child1 // self.SPLIT_VALUE\n",
        "        child1_low = child1 % self.SPLIT_VALUE\n",
        "        child2_high = child2 // self.SPLIT_VALUE\n",
        "        child2_low = child2 % self.SPLIT_VALUE\n",
        "        \n",
        "        return (child1_high, child1_low), (child2_high, child2_low)\n",
        "    \n",
        "    def mutate(self, ind_high, ind_low, min_range, max_range):\n",
        "        \"\"\"Muta√ß√£o adaptativa para representa√ß√£o em duas partes\"\"\"\n",
        "        # Reconstruir o valor completo\n",
        "        individual = ind_high * self.SPLIT_VALUE + ind_low\n",
        "        \n",
        "        if random.random() > self.mutation_rate:\n",
        "            return ind_high, ind_low\n",
        "        \n",
        "        # Diferentes tipos de muta√ß√£o\n",
        "        mutation_type = random.choice(['bit_flip', 'arithmetic', 'gaussian'])\n",
        "        \n",
        "        if mutation_type == 'bit_flip':\n",
        "            # Flip de bit aleat√≥rio\n",
        "            bit_pos = random.randint(0, 70)\n",
        "            result = individual ^ (1 << bit_pos)\n",
        "        \n",
        "        elif mutation_type == 'arithmetic':\n",
        "            # Muta√ß√£o aritm√©tica\n",
        "            delta = random.randint(-2**20, 2**20)\n",
        "            result = max(min_range, min(max_range, individual + delta))\n",
        "        \n",
        "        else:  # gaussian\n",
        "            # Muta√ß√£o gaussiana\n",
        "            std_dev = (max_range - min_range) * 0.01\n",
        "            delta = int(random.gauss(0, std_dev))\n",
        "            result = max(min_range, min(max_range, individual + delta))\n",
        "        \n",
        "        # Dividir o resultado novamente\n",
        "        return result // self.SPLIT_VALUE, result % self.SPLIT_VALUE\n",
        "    \n",
        "    def evolve(self, min_range, max_range):\n",
        "        \"\"\"Uma gera√ß√£o de evolu√ß√£o com suporte a m√∫ltiplas GPUs\"\"\"\n",
        "        # Se temos m√∫ltiplas GPUs, dividir o processo de evolu√ß√£o\n",
        "        if GPU_COUNT > 1 and torch.cuda.is_available():\n",
        "            return self._evolve_multi_gpu(min_range, max_range)\n",
        "        else:\n",
        "            return self._evolve_single_device(min_range, max_range)\n",
        "            \n",
        "    def _evolve_single_device(self, min_range, max_range):\n",
        "        \"\"\"Evolu√ß√£o em um √∫nico dispositivo\"\"\"\n",
        "        # Sele√ß√£o\n",
        "        selected = self.selection()\n",
        "        selected_high, selected_low = selected\n",
        "        \n",
        "        # Crossover e muta√ß√£o\n",
        "        new_population_high = []\n",
        "        new_population_low = []\n",
        "        \n",
        "        for i in range(0, self.population_size, 2):\n",
        "            parent1_high = selected_high[i].item()\n",
        "            parent1_low = selected_low[i].item()\n",
        "            \n",
        "            # Garantir √≠ndice v√°lido para parent2\n",
        "            j = min(i+1, self.population_size-1)\n",
        "            parent2_high = selected_high[j].item()\n",
        "            parent2_low = selected_low[j].item()\n",
        "            \n",
        "            # Crossover\n",
        "            (child1_high, child1_low), (child2_high, child2_low) = self.crossover(\n",
        "                parent1_high, parent1_low, parent2_high, parent2_low\n",
        "            )\n",
        "            \n",
        "            # Muta√ß√£o\n",
        "            child1_high, child1_low = self.mutate(child1_high, child1_low, min_range, max_range)\n",
        "            child2_high, child2_low = self.mutate(child2_high, child2_low, min_range, max_range)\n",
        "            \n",
        "            new_population_high.extend([child1_high, child2_high])\n",
        "            new_population_low.extend([child1_low, child2_low])\n",
        "        \n",
        "        # Manter os melhores (elitismo)\n",
        "        elite_size = self.population_size // 10\n",
        "        elite_indices = torch.topk(self.fitness_scores, elite_size).indices\n",
        "        \n",
        "        high_tensor, low_tensor = self.population\n",
        "        elite_high = high_tensor[elite_indices].cpu().numpy()\n",
        "        elite_low = low_tensor[elite_indices].cpu().numpy()\n",
        "        \n",
        "        # Nova popula√ß√£o\n",
        "        new_population_high = new_population_high[:self.population_size - elite_size]\n",
        "        new_population_low = new_population_low[:self.population_size - elite_size]\n",
        "        \n",
        "        new_population_high.extend(elite_high)\n",
        "        new_population_low.extend(elite_low)\n",
        "        \n",
        "        # Atualizar popula√ß√£o\n",
        "        self.population = (\n",
        "            torch.tensor(new_population_high[:self.population_size], dtype=torch.int64, device=self.main_device),\n",
        "            torch.tensor(new_population_low[:self.population_size], dtype=torch.int64, device=self.main_device)\n",
        "        )\n",
        "        self.generation += 1\n",
        "        \n",
        "        return self.population\n",
        "        \n",
        "    def _evolve_multi_gpu(self, min_range, max_range):\n",
        "        \"\"\"Evolu√ß√£o utilizando m√∫ltiplas GPUs\"\"\"\n",
        "        # Sele√ß√£o\n",
        "        selected = self.selection()\n",
        "        selected_high, selected_low = selected\n",
        "        \n",
        "        # Dividir o trabalho de evolu√ß√£o entre GPUs\n",
        "        chunk_size = self.population_size // (2 * GPU_COUNT)  # Evoluir em pares\n",
        "        futures = []\n",
        "        \n",
        "        with ThreadPoolExecutor(max_workers=GPU_COUNT) as executor:\n",
        "            for gpu_id in range(GPU_COUNT):\n",
        "                start_idx = gpu_id * chunk_size * 2\n",
        "                end_idx = min((gpu_id + 1) * chunk_size * 2, self.population_size)\n",
        "                \n",
        "                if start_idx >= self.population_size:\n",
        "                    break\n",
        "                    \n",
        "                # Enviar um chunk para cada GPU\n",
        "                futures.append(executor.submit(\n",
        "                    self._evolve_population_chunk,\n",
        "                    selected_high[start_idx:end_idx],\n",
        "                    selected_low[start_idx:end_idx],\n",
        "                    min_range,\n",
        "                    max_range,\n",
        "                    gpu_id\n",
        "                ))\n",
        "        \n",
        "        # Coletar resultados\n",
        "        new_high = []\n",
        "        new_low = []\n",
        "        \n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            chunk_high, chunk_low = future.result()\n",
        "            new_high.extend(chunk_high)\n",
        "            new_low.extend(chunk_low)\n",
        "            \n",
        "        # Garantir comprimento consistente\n",
        "        new_high = new_high[:self.population_size - len(new_high) % 2]\n",
        "        new_low = new_low[:self.population_size - len(new_low) % 2]\n",
        "        \n",
        "        # Manter os melhores (elitismo)\n",
        "        elite_size = self.population_size // 10\n",
        "        elite_indices = torch.topk(self.fitness_scores, elite_size).indices\n",
        "        \n",
        "        high_tensor, low_tensor = self.population\n",
        "        elite_high = high_tensor[elite_indices].cpu().numpy()\n",
        "        elite_low = low_tensor[elite_indices].cpu().numpy()\n",
        "        \n",
        "        # Nova popula√ß√£o\n",
        "        new_high = new_high[:self.population_size - elite_size]\n",
        "        new_low = new_low[:self.population_size - elite_size]\n",
        "        \n",
        "        # Adicionar elites\n",
        "        new_high.extend(elite_high)\n",
        "        new_low.extend(elite_low)\n",
        "        \n",
        "        # Atualizar popula√ß√£o\n",
        "        self.population = (\n",
        "            torch.tensor(new_high[:self.population_size], dtype=torch.int64, device=self.main_device),\n",
        "            torch.tensor(new_low[:self.population_size], dtype=torch.int64, device=self.main_device)\n",
        "        )\n",
        "        self.generation += 1\n",
        "        \n",
        "        return self.population\n",
        "        \n",
        "    def _evolve_population_chunk(self, selected_high, selected_low, min_range, max_range, device_id):\n",
        "        \"\"\"Evolui um chunk da popula√ß√£o em uma GPU espec√≠fica\"\"\"\n",
        "        device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        new_high = []\n",
        "        new_low = []\n",
        "        \n",
        "        # Processar pares\n",
        "        for i in range(0, len(selected_high), 2):\n",
        "            if i + 1 >= len(selected_high):  # Se tamanho √≠mpar\n",
        "                break\n",
        "                \n",
        "            parent1_high = selected_high[i].item()\n",
        "            parent1_low = selected_low[i].item()\n",
        "            \n",
        "            parent2_high = selected_high[i+1].item()\n",
        "            parent2_low = selected_low[i+1].item()\n",
        "            \n",
        "            # Crossover\n",
        "            (child1_high, child1_low), (child2_high, child2_low) = self.crossover(\n",
        "                parent1_high, parent1_low, parent2_high, parent2_low\n",
        "            )\n",
        "            \n",
        "            # Muta√ß√£o\n",
        "            child1_high, child1_low = self.mutate(child1_high, child1_low, min_range, max_range)\n",
        "            child2_high, child2_low = self.mutate(child2_high, child2_low, min_range, max_range)\n",
        "            \n",
        "            new_high.extend([child1_high, child2_high])\n",
        "            new_low.extend([child1_low, child2_low])\n",
        "            \n",
        "        return new_high, new_low\n",
        "\n",
        "print(\"GeneticAlgorithm carregado com otimiza√ß√µes multi-GPU avan√ßadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32eb9b42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARTE 6: Execu√ß√£o Automatizada Multi-GPU\n",
        "\n",
        "class BitcoinPuzzleSolver:\n",
        "    def __init__(self, target_address, min_range, max_range, batch_size=None, population_size=None):\n",
        "        self.target_address = target_address\n",
        "        self.min_range = min_range\n",
        "        self.max_range = max_range\n",
        "        \n",
        "        # Configurar tamanhos baseados no n√∫mero de GPUs dispon√≠veis\n",
        "        if batch_size is None:\n",
        "            self.batch_size = DEFAULT_BATCH_SIZE * max(1, GPU_COUNT)\n",
        "        else:\n",
        "            self.batch_size = batch_size\n",
        "            \n",
        "        if population_size is None:\n",
        "            self.population_size = DEFAULT_POPULATION_SIZE * max(1, GPU_COUNT)\n",
        "        else:\n",
        "            self.population_size = population_size\n",
        "            \n",
        "        # Registro de regi√µes exploradas\n",
        "        self.explored_regions = set()\n",
        "        self.best_candidates = []\n",
        "        \n",
        "        # Estat√≠sticas\n",
        "        self.total_keys_checked = 0\n",
        "        self.total_batches = 0\n",
        "        self.start_time = None\n",
        "        self.last_report_time = None\n",
        "        self.report_interval = 10  # segundos\n",
        "        \n",
        "        # Inicializar geradores e algoritmos\n",
        "        self.key_generator = SmartKeyGenerator(min_range, max_range, MAIN_DEVICE)\n",
        "        self.genetic_algorithm = GeneticAlgorithm(self.population_size, device=MAIN_DEVICE)\n",
        "        \n",
        "        # Criar diret√≥rio para pontos de salvamento\n",
        "        self.checkpoint_dir = Path('./checkpoints')\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "        \n",
        "        logger.info(f\"Inicializando solver para o endere√ßo: {target_address}\")\n",
        "        # Calcular base-2 logaritmo manualmente para evitar problemas com n√∫meros grandes\n",
        "        min_pow = 0\n",
        "        temp_min = min_range\n",
        "        while temp_min > 1:\n",
        "            temp_min //= 2\n",
        "            min_pow += 1\n",
        "            \n",
        "        max_pow = 0\n",
        "        temp_max = max_range\n",
        "        while temp_max > 1:\n",
        "            temp_max //= 2\n",
        "            max_pow += 1\n",
        "            \n",
        "        logger.info(f\"Range: 2^{min_pow} a 2^{max_pow}\")\n",
        "        logger.info(f\"Batch size: {self.batch_size:,} | Popula√ß√£o: {self.population_size:,}\")\n",
        "        logger.info(f\"GPUs dispon√≠veis: {GPU_COUNT}\")\n",
        "        \n",
        "    def run_genetic_search(self, max_generations=10):\n",
        "        \"\"\"Executa busca gen√©tica para encontrar o endere√ßo\"\"\"\n",
        "        logger.info(f\"Iniciando busca gen√©tica por at√© {max_generations} gera√ß√µes\")\n",
        "        \n",
        "        # Inicializar popula√ß√£o\n",
        "        self.genetic_algorithm.initialize_population(self.min_range, self.max_range)\n",
        "        \n",
        "        best_fitness = 0\n",
        "        best_key = None\n",
        "        \n",
        "        # Loop principal por gera√ß√µes\n",
        "        for generation in range(max_generations):\n",
        "            # Avaliar fitness da popula√ß√£o atual\n",
        "            fitness_scores = self.genetic_algorithm.evaluate_fitness_batch(self.target_address)\n",
        "            \n",
        "            # Checar melhor resultado\n",
        "            max_fitness = torch.max(fitness_scores).item()\n",
        "            if max_fitness > best_fitness:\n",
        "                best_fitness = max_fitness\n",
        "                best_idx = torch.argmax(fitness_scores).item()\n",
        "                \n",
        "                # Obter a chave com melhor fitness\n",
        "                high, low = self.genetic_algorithm.population\n",
        "                best_high = high[best_idx].item()\n",
        "                best_low = low[best_idx].item()\n",
        "                best_key = best_high * (2**32) + best_low\n",
        "                \n",
        "                logger.info(f\"Gera√ß√£o {generation}: Melhor fitness = {best_fitness:.6f} | Chave: {best_key}\")\n",
        "                \n",
        "                # Se encontrou solu√ß√£o (fitness muito alto)\n",
        "                if max_fitness > 0.9999:\n",
        "                    logger.info(f\"üéâ CHAVE ENCONTRADA: {best_key}\")\n",
        "                    return best_key\n",
        "            \n",
        "            # Se n√£o √© a √∫ltima gera√ß√£o, evoluir para a pr√≥xima\n",
        "            if generation < max_generations - 1:\n",
        "                self.genetic_algorithm.evolve(self.min_range, self.max_range)\n",
        "                \n",
        "        return best_key\n",
        "    \n",
        "    def run_multi_strategy_search(self, num_batches=100, strategies=None):\n",
        "        \"\"\"Executa busca usando m√∫ltiplas estrat√©gias em paralelo\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        self.last_report_time = self.start_time\n",
        "        \n",
        "        if strategies is None:\n",
        "            strategies = ['adaptive', 'fibonacci', 'quantum_inspired', 'random']\n",
        "            \n",
        "        logger.info(f\"Iniciando busca multi-estrat√©gia por {num_batches} lotes\")\n",
        "        logger.info(f\"Usando estrat√©gias: {strategies}\")\n",
        "        \n",
        "        # Verificar ambiente antes de iniciar\n",
        "        if torch.cuda.is_available():\n",
        "            logger.info(f\"Utilizando {torch.cuda.device_count()} GPU(s)\")\n",
        "            for i in range(torch.cuda.device_count()):\n",
        "                logger.info(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        else:\n",
        "            logger.info(\"Modo CPU: Nenhuma GPU dispon√≠vel\")\n",
        "            \n",
        "        # Verificar se temos dispositivos consistentes\n",
        "        if GPU_COUNT > 0 and len(DEVICES) != GPU_COUNT:\n",
        "            logger.warning(f\"Inconsist√™ncia detectada: GPU_COUNT={GPU_COUNT}, mas DEVICES tem {len(DEVICES)} elementos\")\n",
        "            logger.warning(\"Corrigindo configura√ß√£o de dispositivos...\")\n",
        "            global DEVICES\n",
        "            DEVICES = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "            if not DEVICES:\n",
        "                DEVICES = [MAIN_DEVICE]\n",
        "        \n",
        "        # Loop principal por lotes\n",
        "        for batch_num in range(num_batches):\n",
        "            # Gerar lote de chaves usando m√∫ltiplas estrat√©gias em paralelo\n",
        "            try:\n",
        "                keys_tensors = self.key_generator.generate_smart_multi_batch(\n",
        "                    self.batch_size, strategies\n",
        "                )\n",
        "            except RuntimeError as e:\n",
        "                if \"Expected all tensors to be on the same device\" in str(e):\n",
        "                    logger.warning(\"Detectado erro de dispositivos inconsistentes. Tentando abordagem alternativa...\")\n",
        "                    # Abordagem alternativa: usar apenas uma estrat√©gia em vez de m√∫ltiplas\n",
        "                    keys_tensors = self.key_generator.generate_smart_batch(\n",
        "                        self.batch_size, strategy=random.choice(strategies)\n",
        "                    )\n",
        "                else:\n",
        "                    # Para outros erros, repassar a exce√ß√£o\n",
        "                    raise\n",
        "            \n",
        "            # Converter chaves para formato adequado para processamento\n",
        "            private_keys = keys_tensors  # J√° em formato de tupla (high, low)\n",
        "            \n",
        "            # Gerar chaves p√∫blicas\n",
        "            public_keys = BitcoinUtils.private_key_to_public_key_batch_gpu(private_keys)\n",
        "            \n",
        "            # Verificar endere√ßos\n",
        "            matches, results = BitcoinUtils.batch_addresses_check(public_keys, self.target_address)\n",
        "            \n",
        "            # Atualizar estat√≠sticas\n",
        "            self.total_keys_checked += self.batch_size\n",
        "            self.total_batches += 1\n",
        "            \n",
        "            # Se encontrou correspond√™ncias\n",
        "            if matches:\n",
        "                # Reconstruir a chave privada original\n",
        "                high, low = private_keys\n",
        "                for i, (addr, _) in enumerate(results):\n",
        "                    if addr == self.target_address:\n",
        "                        private_key = high[i].item() * (2**32) + low[i].item()\n",
        "                        logger.info(f\"üéâ CHAVE ENCONTRADA: {private_key}\")\n",
        "                        return private_key\n",
        "            \n",
        "            # Relat√≥rio de progresso\n",
        "            current_time = time.time()\n",
        "            if current_time - self.last_report_time >= self.report_interval:\n",
        "                self._report_progress(batch_num, num_batches)\n",
        "                self.last_report_time = current_time\n",
        "                \n",
        "            # A cada 10 lotes, tentar abordagem gen√©tica\n",
        "            if batch_num > 0 and batch_num % 10 == 0:\n",
        "                logger.info(\"Executando busca gen√©tica complementar...\")\n",
        "                key = self.run_genetic_search(max_generations=3)\n",
        "                if key is not None:\n",
        "                    return key\n",
        "                    \n",
        "        logger.info(\"Busca conclu√≠da sem encontrar a chave.\")\n",
        "        return None\n",
        "    \n",
        "    def _report_progress(self, batch_num, total_batches):\n",
        "        \"\"\"Relata progresso da busca\"\"\"\n",
        "        elapsed = time.time() - self.start_time\n",
        "        keys_per_second = self.total_keys_checked / elapsed if elapsed > 0 else 0\n",
        "        percent_complete = (batch_num + 1) / total_batches * 100 if total_batches > 0 else 0\n",
        "        \n",
        "        logger.info(f\"Progresso: {percent_complete:.2f}% | Lote: {batch_num+1}/{total_batches}\")\n",
        "        logger.info(f\"Chaves verificadas: {self.total_keys_checked:,} | Velocidade: {keys_per_second:.2f} chaves/s\")\n",
        "        logger.info(f\"Tempo decorrido: {elapsed:.2f}s\")\n",
        "\n",
        "# Inicializar e executar o solver\n",
        "puzzle_solver = BitcoinPuzzleSolver(\n",
        "    target_address=PUZZLE_71_CONFIG['target_address'],\n",
        "    min_range=PUZZLE_71_CONFIG['min_range'],\n",
        "    max_range=PUZZLE_71_CONFIG['max_range'],\n",
        "    batch_size=PUZZLE_71_CONFIG['batch_size'],\n",
        "    population_size=PUZZLE_71_CONFIG['population_size']\n",
        ")\n",
        "\n",
        "print(\"üîç Iniciando busca automatizada pela chave privada do Puzzle 71...\")\n",
        "print(f\"üéØ Endere√ßo alvo: {PUZZLE_71_CONFIG['target_address']}\")\n",
        "print(f\"üìä Usando {GPU_COUNT} GPU(s) e {NUM_THREADS} threads\")\n",
        "\n",
        "# Configurar n√∫mero de lotes com base no ambiente\n",
        "num_batches = 1000 if torch.cuda.is_available() else 100\n",
        "\n",
        "# Executar busca com m√∫ltiplas estrat√©gias\n",
        "found_key = puzzle_solver.run_multi_strategy_search(num_batches=num_batches)\n",
        "\n",
        "if found_key:\n",
        "    print(f\"\\nüéâüéâüéâ CHAVE ENCONTRADA: {found_key}\")\n",
        "    print(f\"üîë Endere√ßo Bitcoin: {PUZZLE_71_CONFIG['target_address']}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Chave n√£o encontrada nesta execu√ß√£o. Tente aumentar o n√∫mero de lotes ou alterar estrat√©gias.\")\n",
        "    print(f\"üìä Total de chaves verificadas: {puzzle_solver.total_keys_checked:,}\")\n",
        "    \n",
        "print(\"\\n‚úÖ Execu√ß√£o conclu√≠da!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f707715f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Assegura que erros CUDA sejam reportados no local exato\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Vari√°veis de ambiente e configura√ß√µes (defina conforme seu ambiente)\n",
        "IS_KAGGLE = \"KAGGLE_URL_BASE\" in os.environ  # True se rodando no Kaggle\n",
        "GPU_COUNT = torch.cuda.device_count()\n",
        "FORCE_GPU = False  # Se quiser for√ßar uso de GPU mesmo fora do Kaggle\n",
        "\n",
        "# Configura√ß√µes do Puzzle 71 (defina antes de chamar)\n",
        "PUZZLE_71_CONFIG = {\n",
        "    'target_address': 'ENDERE√áO_ALVO_AQUI',\n",
        "    'min_range': 0x40000000,\n",
        "    'max_range': 0x7FFFFFFFFFFFFFFF,\n",
        "    'batch_size': 1024,\n",
        "    'population_size': 1000\n",
        "}\n",
        "\n",
        "# Placeholder para a classe BitcoinPuzzleSolver (importe ou defina antes de usar)\n",
        "class BitcoinPuzzleSolver:\n",
        "    def __init__(self, target_address, min_range, max_range, batch_size=None, population_size=None, device=None):\n",
        "        self.target_address = target_address\n",
        "        self.min_range = min_range\n",
        "        self.max_range = max_range\n",
        "        self.batch_size = batch_size\n",
        "        self.population_size = population_size\n",
        "        self.device = device or (torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "\n",
        "    def run_genetic_search(self, max_generations=10):\n",
        "        best_key = None\n",
        "        for gen in range(max_generations):\n",
        "            # L√≥gica do algoritmo gen√©tico na GPU atribu√≠da\n",
        "            pass\n",
        "        return best_key\n",
        "\n",
        "    def run_multi_strategy_search(self, num_batches=100, strategies=None):\n",
        "        for batch_num in range(num_batches):\n",
        "            # L√≥gica da busca multi-estrat√©gia na GPU atribu√≠da\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "def run_kaggle_optimized():\n",
        "    print(\"üöÄ Iniciando busca otimizada para ambiente Kaggle (Dual-GPU)...\")\n",
        "\n",
        "    genetic_config = {\n",
        "        'target_address': PUZZLE_71_CONFIG['target_address'],\n",
        "        'min_range': PUZZLE_71_CONFIG['min_range'],\n",
        "        'max_range': PUZZLE_71_CONFIG['max_range'],\n",
        "        'batch_size': PUZZLE_71_CONFIG['batch_size'] // 2,\n",
        "        'population_size': PUZZLE_71_CONFIG['population_size'] * 2,\n",
        "        'device': torch.device(\"cuda:0\")\n",
        "    }\n",
        "\n",
        "    multi_config = {\n",
        "        'target_address': PUZZLE_71_CONFIG['target_address'],\n",
        "        'min_range': PUZZLE_71_CONFIG['min_range'],\n",
        "        'max_range': PUZZLE_71_CONFIG['max_range'],\n",
        "        'batch_size': PUZZLE_71_CONFIG['batch_size'] * 2,\n",
        "        'population_size': PUZZLE_71_CONFIG['population_size'] // 2,\n",
        "        'device': torch.device(\"cuda:1\")\n",
        "    }\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        genetic_solver = BitcoinPuzzleSolver(**genetic_config)\n",
        "        multi_solver = BitcoinPuzzleSolver(**multi_config)\n",
        "\n",
        "        print(\"üß¨ Iniciando solver gen√©tico na GPU 0...\")\n",
        "        print(\"üîç Iniciando solver multi-estrat√©gia na GPU 1...\")\n",
        "\n",
        "        future_genetic = executor.submit(genetic_solver.run_genetic_search, 50)\n",
        "        future_multi = executor.submit(multi_solver.run_multi_strategy_search, 500, ['adaptive', 'fibonacci', 'quantum_inspired'])\n",
        "\n",
        "        result = None\n",
        "        while True:\n",
        "            if future_genetic.done():\n",
        "                try:\n",
        "                    key_g = future_genetic.result()\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erro no solver gen√©tico (GPU 0): {e}\")\n",
        "                    key_g = None\n",
        "                if key_g:\n",
        "                    print(\"üéØ Solver gen√©tico encontrou a chave!\")\n",
        "                    result = key_g\n",
        "                    break\n",
        "            if future_multi.done():\n",
        "                try:\n",
        "                    key_m = future_multi.result()\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erro no solver multi-estrat√©gia (GPU 1): {e}\")\n",
        "                    key_m = None\n",
        "                if key_m:\n",
        "                    print(\"üéØ Solver multi-estrat√©gia encontrou a chave!\")\n",
        "                    result = key_m\n",
        "                    break\n",
        "            if future_genetic.done() and future_multi.done():\n",
        "                break\n",
        "            time.sleep(1)\n",
        "\n",
        "        print(\"\\n‚è±Ô∏è Finalizando todos os solvers...\")\n",
        "        return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if (IS_KAGGLE and GPU_COUNT > 1) or FORCE_GPU:\n",
        "        print(f\"üñ•Ô∏è Ambiente Kaggle detectado com {GPU_COUNT} GPUs\")\n",
        "        print(\"‚ñ∂Ô∏è Iniciando execu√ß√£o otimizada para dual-GPU...\\n\")\n",
        "        found_key = run_kaggle_optimized()\n",
        "        if found_key:\n",
        "            print(f\"\\nüéâüéâüéâ CHAVE ENCONTRADA: {found_key}\")\n",
        "            print(f\"üîë Endere√ßo Bitcoin: {PUZZLE_71_CONFIG['target_address']}\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è Chave n√£o encontrada. Tente executar novamente.\")\n",
        "    else:\n",
        "        print(\"‚öôÔ∏è Executando em modo padr√£o (n√£o-Kaggle ou single-GPU)...\")\n",
        "    print(\"\\n‚úÖ Execu√ß√£o final conclu√≠da!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}